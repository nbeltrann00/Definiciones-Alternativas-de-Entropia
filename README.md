<p align="center">
  <img src="https://img.shields.io/badge/ENTROPÃA-TERMODINÃMICA%20%7C%20INFORMACIÃ“N%20%7C%20CUÃNTICA-blueviolet?style=for-the-badge&logo=python&logoColor=white" />
</p>

<h1 align="center">ğŸ“˜ Proyecto: ENTROPÃA</h1>

<p align="center">
  <b>DispersiÃ³n de la energÃ­a â€¢ Microestados â€¢ Shannon â€¢ Entrelazamiento â€¢ Dimensionalidad</b>
</p>

<hr>


# Definiciones-Alternativas-de-Entropia
EntropÃ­a â€“ Repositorio
DefiniciÃ³n de la entropÃ­a como la dispersiÃ³n de la energÃ­a

Para tener una definiciÃ³n mÃ¡s moderna de la entropÃ­a, la definen Atkins y De Paula (2008) como la medida del grado de disipaciÃ³n de la energÃ­a en un sistema y alrededores,

En palabras textuales:

â€œUna interpretaciÃ³n mÃ¡s satisfactoria de la entropÃ­a, es como medida de la disipaciÃ³n de la energÃ­a. Cuando ocurre un cambio, la energÃ­a se disipa mÃ¡s y la entropÃ­a aumenta. asÃ­ la segunda ley de la termodinÃ¡mica es, por lo tanto, la afirmaciÃ³n de que la energÃ­a tiene a disiparse y que existe una direcciÃ³n natural del cambio en la que la energÃ­a queda cada vez mÃ¡s disipada.â€
(Atkins y De Paula, 2008, pÃ¡g. 77-78)

TambiÃ©n incluyen el criterio universal del cambio espontaneo:

â€œHemos encontrado la seÃ±al indicadora del cambio espontaneo: buscamos la direcciÃ³n del cambio que conduce la disipaciÃ³n de energÃ­a total del sistema aisladoâ€
(Atkins & de Paula, 2008, p. 78)

Podemos definir la entropÃ­a S como la funciÃ³n de estado que cuantifica el grado en el que la energÃ­a de un proceso se ha disipado o distribuido entre todos los microestados accesibles del sistema y sus alrededores.

Un proceso espontÃ¡neo ocurre siempre en la direcciÃ³n en la que la energÃ­a total se disipa mÃ¡s, es decir, aquella en la que la variaciÃ³n de la entropÃ­a total del universo es mayor que cero:

Î”
ğ‘†
tot
=
ğ‘†
sistema
+
ğ‘†
alrededores
>
0
Î”S
tot
	â€‹

=S
sistema
	â€‹

+S
alrededores
	â€‹

>0

Resumiendo, asÃ­ la segunda ley como:

Î”
ğ‘†
tot
>
0
Î”S
tot
	â€‹

>0
EJERCICIOS PRÃCTICOS
Enunciado 1: Un cubito de hielo a 0 Â°C se pone en agua a 25 Â°C

La energÃ­a tÃ©rmica del agua tibia se reparte hacia el hielo (lo derrite) y queda distribuida entre muchas mÃ¡s molÃ©culas en forma lÃ­quida.
â†’ La energÃ­a total se disipa mÃ¡s que antes
â†’ Î”S_tot > 0
â†’ Proceso espontÃ¡neo.

El proceso inverso (el agua lÃ­quida se congela sola sacando calor al ambiente mÃ¡s caliente) nunca ocurre porque disminuirÃ­a la disipaciÃ³n total de energÃ­a.

Enunciado 2: Mezcla de gases

Un recipiente dividido en dos partes: una con helio y otra con neÃ³n (misma T y P). Se quita la pared divisoria.

Las molÃ©culas de cada gas, que antes estaban confinadas en la mitad del volumen, ahora ocupan todo el recipiente.
â†’ La energÃ­a cinÃ©tica de traslaciÃ³n se reparte en un volumen mayor nÃºmero de posiciones posibles
â†’ La energÃ­a se disipa mÃ¡s
â†’ Î”S_tot > 0
â†’ La mezcla es espontÃ¡nea.

Nunca se ve que los gases se separen solos, porque eso concentrarÃ­a la energÃ­a en menos microestados.

EntropÃ­a como distribuciÃ³n de microestados

En la termodinÃ¡mica estadÃ­stica, la entropÃ­a cuantifica la multiplicidad de microestados accesibles a un macroestado especificado por variables extensivas como energÃ­a, volumen y nÃºmero de partÃ­culas. Esta formulaciÃ³n, propuesta por Ludwig Boltzmann, fundamenta la irreversibilidad termodinÃ¡mica en el principio de mÃ¡xima probabilidad, donde los macroestados de alta entropÃ­a dominan debido a su superior degeneraciÃ³n microscÃ³pica (Reif, 1965).

Microestados y Macroestados

Un microestado es como una â€œfoto instantÃ¡nea completaâ€ de todo lo que pasa dentro del sistema: la posiciÃ³n exacta (q) y la velocidad (p) de cada una de las N partÃ­culas.

El macroestado es una â€œregiÃ³n grandeâ€ en el espacio fase (Î”Î“), que agrupa muchos microestados parecidos.

Entonces, Î© (el nÃºmero de microestados) se calcula como el tamaÃ±o de esa regiÃ³n dividido por:

â„
3
ğ‘
ğ‘
!
h
3N
N!

Finalmente:

ğ‘†
=
ğ‘˜
ğµ
ln
â¡
Î©
S=k
B
	â€‹

lnÎ©

Cuando N es muy grande, esta S se comporta como una propiedad extensiva (que suma al juntar sistemas).

La Segunda Ley, al Natural

La segunda ley dice que la entropÃ­a nunca baja (Î”S â‰¥ 0) en un sistema aislado.
Â¿Por quÃ©? Porque Î© (nÃºmero de microestados) solo puede aumentar o quedarse igual.

Ejemplos prÃ¡cticos
Ejemplo 1: EntropÃ­a de 20 monedas

Estado: 10 caras y 10 cruces.

Î©
=
(
20
10
)
Î©=(
10
20
	â€‹

)
ğ‘†
=
ğ‘˜
ğµ
ln
â¡
Î©
S=k
B
	â€‹

lnÎ©

MÃ¡xima entropÃ­a:

ğ‘†
max
=
20
ğ‘˜
ğµ
ln
â¡
2
S
max
	â€‹

=20k
B
	â€‹

ln2

ConclusiÃ³n: Es el macroestado mÃ¡s probable.

Ejemplo 2: Gas ideal expandiÃ©ndose

4 partÃ­culas, 2 compartimentos.

Estado inicial: todas a la izquierda â†’ Î© = 1
Estado final: distribuciÃ³n libre â†’ Î© â‰ˆ 16
Î”S > 0 â†’ espontÃ¡neo

EntropÃ­a como calidad de informaciÃ³n (Shannon)

Shannon (1948) define la entropÃ­a como incertidumbre promedio:

ğ»
=
âˆ’
âˆ‘
ğ‘
ğ‘–
log
â¡
2
ğ‘
ğ‘–
H=âˆ’âˆ‘p
i
	â€‹

log
2
	â€‹

p
i
	â€‹


Propiedades:

MÃ¡xima cuando todos los eventos son equiprobables.

Cero cuando un evento es seguro.

Concavidad: mezclar aumenta la entropÃ­a.

ConexiÃ³n con fÃ­sica

Jaynes (1957) mostrÃ³ que si todos los microestados tienen probabilidad igual, Shannon y Boltzmann se vuelven equivalentes:

ğ‘†
=
ğ‘˜
ğµ
ln
â¡
Î©
S=k
B
	â€‹

lnÎ©
Ejemplos de Shannon
Ejemplo 1: Moneda sesgada

P(cara)=0.9, P(cruz)=0.1.

H < 1 bit â†’ mÃ¡s predecible.

Ejemplo 2: CompresiÃ³n de texto con Huffman

Ejemplo trabajado:
Frecuencias de letras (e, t, a, o, i, n, r, s)
ConstrucciÃ³n del Ã¡rbol Huffman
CÃ³digos Ã³ptimos
Tasa promedio â‰ˆ 3.05 bits
ASCII = 8 bits
â†’ CompresiÃ³n ~62%

EntropÃ­a como entrelazamiento cuÃ¡ntico

La entropÃ­a cuÃ¡ntica de von Neumann:

ğ‘†
(
ğœŒ
)
=
âˆ’
Tr
(
ğœŒ
ln
â¡
ğœŒ
)
S(Ï)=âˆ’Tr(ÏlnÏ)

Propiedades:

Estado puro: S = 0

Estado totalmente mezclado: S mÃ¡xima

Subaditividad

Mide el grado de entrelazamiento

Ejemplo 1: Par de Bell

Sistema total: S = 0
Cada qubit individual: S = 1
â†’ mÃ¡ximo entrelazamiento.

Ejemplo 2: Qubits con magnetizaciÃ³n parcial

Se muestran valores comparativos de entropÃ­a:

Estado	S_total	S_A	S_B	Entrelazamiento
Bell	0	1	1	MÃ¡ximo
Separado	0.32	0.50	0.50	Bajo
Producto	0.32	0.11	0.32	Ninguno
EntropÃ­a como funciÃ³n de la dimensionalidad

En espacios de alta dimensiÃ³n:

El volumen se concentra en la superficie.

La entropÃ­a crece extremadamente rÃ¡pido.

Ejemplo:
Hipercubo en D dimensiones
Volumen efectivo en superficie para D > 10
H âˆ D Ã— 2^D

RelaciÃ³n con el Principio HologrÃ¡fico

En gravedad cuÃ¡ntica:

ğ‘†
âˆ
ğ´
SâˆA

(Ã¡rea, no volumen)

Maldacena (1998): AdS/CFT
â€™t Hooft (1993): ReducciÃ³n dimensional
Susskind (1995): Mundos hologrÃ¡ficos

DefiniciÃ³n y ecuaciÃ³n de la segunda ley de la termodinÃ¡mica

La segunda ley indica que la entropÃ­a total del universo aumenta en procesos espontÃ¡neos.

SegÃºn Chemistry (Flowers et al., 2015):

Definiciones:
Î”
ğ‘†
=
ğ‘†
final
âˆ’
ğ‘†
inicial
Î”S=S
final
	â€‹

âˆ’S
inicial
	â€‹

Î”
ğ‘†
univ
=
Î”
ğ‘†
sis
+
Î”
ğ‘†
alr
Î”S
univ
	â€‹

=Î”S
sis
	â€‹

+Î”S
alr
	â€‹

Î”
ğ‘†
alr
=
âˆ’
Î”
ğ»
sis
ğ‘‡
Î”S
alr
	â€‹

=
T
âˆ’Î”H
sis
	â€‹

	â€‹


Criterios:

Î”S_univ > 0 â†’ espontÃ¡neo

Î”S_univ < 0 â†’ no espontÃ¡neo

Î”S_univ = 0 â†’ reversible

Ejemplo: CongelaciÃ³n del agua
ParÃ¡metro	CÃ¡lculo	Resultado
Î”S_alr	(-Î”H_sis)/T = -(-6000 J)/263.15 K	+22.80 J/K
Î”S_univ	Î”S_sis + Î”S_alr = -22.1 + 22.80	+0.70 J/K

â†’ EspontÃ¡neo a -10Â°C

ParÃ¡metro	CÃ¡lculo	Resultado
Î”S_alr	-(-6000)/273.16	+21.97 J/K
Î”S_univ	-22.1 + 21.97	-0.13 J/K

â†’ No espontÃ¡neo a +10Â°C
